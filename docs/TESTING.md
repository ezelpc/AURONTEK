# Manual de Pruebas - Sistema AURONTEK

## üìã √çndice

1. [Instalaci√≥n de Dependencias](#instalaci√≥n-de-dependencias)
2. [Ejecutar Pruebas Localmente](#ejecutar-pruebas-localmente)
3. [Interpretar Resultados](#interpretar-resultados)
4. [Dashboard y Reportes](#dashboard-y-reportes)
5. [Integraci√≥n CI/CD](#integraci√≥n-cicd)
6. [Troubleshooting](#troubleshooting)

---

## 1. Instalaci√≥n de Dependencias

### Backend - Servicios Node.js

```bash
# Navegar a cada servicio e instalar dependencias
cd backend/usuarios-svc
npm install

cd ../tickets-svc
npm install

cd ../gateway-svc
npm install
```

### Backend - Servicio Python (ia-svc)

```bash
cd backend/ia-svc
pip install -r requirements.txt

# Instalar dependencias de testing
pip install pytest pytest-asyncio pytest-cov pytest-mock scikit-learn
```

### Dashboard de Reportes

```bash
cd backend/test-dashboard
npm install
```

---

## 2. Ejecutar Pruebas Localmente

### 2.1 Pruebas Unitarias - usuarios-svc

```bash
cd backend/usuarios-svc

# Ejecutar todos los tests
npm test

# Ejecutar solo tests unitarios
npm run test:unit

# Ejecutar con cobertura
npm run test:coverage

# Modo watch (re-ejecuta al guardar cambios)
npm run test:watch
```

**Tests incluidos:**
- ‚úÖ Generaci√≥n de c√≥digos de acceso
- ‚úÖ Hashing de contrase√±as con bcrypt
- ‚úÖ Generaci√≥n y validaci√≥n de JWT tokens

**Ubicaci√≥n:** `backend/usuarios-svc/__tests__/unit/utils.test.ts`

---

### 2.2 Pruebas Unitarias - tickets-svc

```bash
cd backend/tickets-svc

# Ejecutar todos los tests
npm test

# Con cobertura
npm run test:coverage
```

**Tests incluidos:**
- ‚úÖ Validaci√≥n de datos de ticket
- ‚úÖ Transiciones de estado (pendiente ‚Üí en_proceso ‚Üí resuelto ‚Üí cerrado)
- ‚úÖ C√°lculo de SLA por prioridad
- ‚úÖ Asignaci√≥n de prioridad por palabras clave

**Ubicaci√≥n:** `backend/tickets-svc/__tests__/unit/ticketValidation.test.ts`

---

### 2.3 Pruebas Unitarias - ia-svc

```bash
cd backend/ia-svc

# Ejecutar todos los tests
pytest

# Con cobertura
pytest --cov=. --cov-report=html

# Ver reporte de cobertura
# Abrir: htmlcov/index.html en navegador

# Ejecutar solo tests unitarios
pytest -m unit

# Modo verbose
pytest -v
```

**Tests incluidos:**
- ‚úÖ C√°lculo de carga de trabajo de agentes
- ‚úÖ Filtrado de agentes disponibles
- ‚úÖ Selecci√≥n por especialidad
- ‚úÖ Priorizaci√≥n por menor carga

**Ubicaci√≥n:** `backend/ia-svc/tests/unit/test_agent_assigner.py`

---

### 2.4 Pruebas Funcionales - gateway-svc

```bash
cd backend/gateway-svc

# Ejecutar tests funcionales
npm run test:functional

# Ejecutar tests de rendimiento
npm run test:performance
```

---

### 2.5 Ejecutar TODOS los Tests

Desde la ra√≠z del proyecto:

```bash
# Opci√≥n 1: Ejecutar manualmente cada servicio
cd backend/usuarios-svc && npm test
cd ../tickets-svc && npm test
cd ../gateway-svc && npm test
cd ../ia-svc && pytest

# Opci√≥n 2: Usar GitHub Actions (recomendado)
# Push a rama 'test' para ejecutar autom√°ticamente
git checkout test
git add .
git commit -m "Run all tests"
git push origin test
```

---

## 3. Interpretar Resultados

### 3.1 Resultados de Jest (Node.js)

```
PASS  __tests__/unit/utils.test.ts
  Utils - Unit Tests
    generarCodigoAcceso
      ‚úì should generate a code with default length of 8 (3 ms)
      ‚úì should generate a code with custom length (1 ms)
      ‚úì should generate alphanumeric code only (2 ms)
    Password Hashing (bcrypt)
      ‚úì should hash password successfully (156 ms)
      ‚úì should verify correct password (145 ms)

Test Suites: 1 passed, 1 total
Tests:       35 passed, 35 total
Snapshots:   0 total
Time:        3.456 s
```

**Interpretaci√≥n:**
- ‚úÖ **PASS**: Todos los tests pasaron
- ‚ùå **FAIL**: Alg√∫n test fall√≥
- **Test Suites**: Archivos de test ejecutados
- **Tests**: N√∫mero total de tests individuales
- **Time**: Tiempo de ejecuci√≥n

### 3.2 Cobertura de C√≥digo

```
---------------------|---------|----------|---------|---------|
File                 | % Stmts | % Branch | % Funcs | % Lines |
---------------------|---------|----------|---------|---------|
All files            |   87.5  |   82.14  |   90.91 |   87.5  |
 src/Utils           |   100   |   100    |   100   |   100   |
  utils.ts           |   100   |   100    |   100   |   100   |
---------------------|---------|----------|---------|---------|
```

**Objetivo:** >80% en todas las m√©tricas

**Interpretaci√≥n:**
- **% Stmts**: Porcentaje de declaraciones ejecutadas
- **% Branch**: Porcentaje de ramas (if/else) cubiertas
- **% Funcs**: Porcentaje de funciones ejecutadas
- **% Lines**: Porcentaje de l√≠neas ejecutadas

---

### 3.3 Resultados de Pytest (Python)

```
============================= test session starts ==============================
collected 15 items

tests/unit/test_agent_assigner.py::TestAgentAssigner::test_calculate_workload_low PASSED [ 6%]
tests/unit/test_agent_assigner.py::TestAgentAssigner::test_calculate_workload_medium PASSED [13%]
...

============================== 15 passed in 0.45s ===============================

---------- coverage: platform win32, python 3.10.11 -----------
Name                              Stmts   Miss  Cover
-----------------------------------------------------
services/agent_assigner.py           45      3    93%
-----------------------------------------------------
TOTAL                                45      3    93%
```

**Interpretaci√≥n:**
- **15 passed**: Todos los tests pasaron
- **Cover**: 93% de cobertura (objetivo >80%)

---

## 4. Dashboard y Reportes

### 4.1 Generar Reportes

```bash
cd backend/test-dashboard

# Generar todos los reportes
node generate-report.js

# Esto crea:
# - docs/testing/reportes/[fecha]/reporte-[fecha].md
# - docs/testing/reportes/[fecha]/data/resultados-tests-[fecha].json
# - docs/testing/reportes/[fecha]/data/resultados-tests-[fecha].csv
```

### 4.2 Ver Dashboard Interactivo

```bash
cd backend/test-dashboard

# Opci√≥n 1: Abrir directamente
# Abrir index.html en navegador

# Opci√≥n 2: Usar servidor local
npx http-server . -p 8080
# Luego abrir: http://localhost:8080
```

**El dashboard muestra:**
- üìä KPIs: Tests pasados, Cobertura, Latencia, Precisi√≥n IA
- üìà Gr√°ficas: Latencia, Tests pasados/fallidos, P95 por servicio
- üìã Tabla de resultados por m√≥dulo

### 4.3 Exportar Reportes

Desde el dashboard:
- **Bot√≥n "Exportar PDF"**: Genera reporte PDF completo
- **Bot√≥n "Exportar CSV"**: Exporta datos tabulares

---

## 5. Integraci√≥n CI/CD

### 5.1 GitHub Actions

El workflow `.github/workflows/test.yml` se ejecuta autom√°ticamente en:
- Push a rama `test`
- Pull Request a rama `test`

**Qu√© hace:**
1. Ejecuta tests de todos los servicios Node.js en paralelo
2. Ejecuta tests de Python (ia-svc)
3. Genera reportes de cobertura
4. Sube artifacts con resultados
5. Comenta resultados en PRs

### 5.2 Ver Resultados en GitHub

1. Ir a tu repositorio en GitHub
2. Click en pesta√±a "Actions"
3. Seleccionar el workflow "Test Suite"
4. Ver resultados de cada job

### 5.3 Descargar Reportes

En la p√°gina del workflow:
1. Scroll hasta "Artifacts"
2. Descargar "test-reports"
3. Descomprimir y revisar reportes

---

## 6. Troubleshooting

### 6.1 Error: "Cannot find module 'jest'"

**Soluci√≥n:**
```bash
cd backend/usuarios-svc
npm install --save-dev jest @types/jest ts-jest
```

### 6.2 Error: "pytest: command not found"

**Soluci√≥n:**
```bash
pip install pytest pytest-asyncio pytest-cov
```

### 6.3 Tests fallan con "MODULE_NOT_FOUND"

**Soluci√≥n:**
```bash
# Limpiar cache y reinstalar
cd backend/usuarios-svc
npm run cache
```

### 6.4 Cobertura menor a 80%

**Soluci√≥n:**
- Revisar qu√© archivos no est√°n cubiertos en el reporte
- Agregar m√°s tests para esas √°reas
- Ver reporte HTML de cobertura: `coverage/index.html`

### 6.5 Tests de Python fallan con import errors

**Soluci√≥n:**
```bash
cd backend/ia-svc
export PYTHONPATH="${PYTHONPATH}:$(pwd)"  # Linux/Mac
set PYTHONPATH=%PYTHONPATH%;%cd%  # Windows
pytest
```

### 6.6 Dashboard no muestra datos

**Soluci√≥n:**
1. Verificar que se ejecutaron los tests
2. Ejecutar `node generate-report.js`
3. Verificar que existen archivos en `docs/testing/reportes/latest/`

---

## üìä Resumen de Comandos R√°pidos

```bash
# Tests Node.js
cd backend/usuarios-svc && npm test
cd backend/tickets-svc && npm test
cd backend/gateway-svc && npm test

# Tests Python
cd backend/ia-svc && pytest

# Generar reportes
cd backend/test-dashboard && node generate-report.js

# Ver dashboard
cd backend/test-dashboard && npx http-server . -p 8080
```

---

## üìù Checklist de Verificaci√≥n

Antes de hacer merge a producci√≥n, verificar:

- [ ] Todos los tests pasan (npm test en cada servicio)
- [ ] Cobertura >80% en todos los servicios
- [ ] Tests de Python pasan (pytest)
- [ ] Dashboard muestra m√©tricas correctas
- [ ] Reportes se generan sin errores
- [ ] GitHub Actions workflow pasa en rama test
- [ ] No hay archivos de test en rama main/production

---

## üÜò Soporte

Si encuentras problemas:
1. Revisar secci√≥n de Troubleshooting
2. Ver logs detallados con `-v` o `--verbose`
3. Verificar versiones de Node.js (>=18) y Python (>=3.8)
4. Limpiar cache y reinstalar dependencias

---

**√öltima actualizaci√≥n:** 2024-12-07
